{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to apply recurrent neural networks to text classification problem in order to predict in which forum on Stackexchnage the question was asked.\n",
    "\n",
    "Please note: \n",
    "\n",
    "- You can interrupt the training process at any time by clicking on *Kernel* and then *Interrupt*.\n",
    "- This notebook has not yet been adapted to Keras 2. If you use Python and don't want to use AWS, please do: `conda install keras==1.1.1 graphviz pydot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the [Keras](http://keras.io) framework that abstracts away a lot of the details of deep learning. We will only use the [funcational API](https://keras.io/getting-started/functional-api-guide/) due to its expressive power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.layers.wrappers import *\n",
    "from keras.optimizers import *\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.visualize_util import plot, model_to_dot\n",
    "from IPython.display import SVG\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has been already preprocessed from raw XML format and saved to csv. However, you must remeber that Keras works on numpy arrays so we will prepare data before feed it to the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_final = pd.read_csv(\"dataset_final.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's focus on columns with questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am trying to model the effect of advertisement on sales in Stata. The data is weekly and there are around 150 observations. I started by applying an ARMAX(1,0,1) model with the following exogenous variables: investment in advertisement, quantities bought by visit and some seasonal dummies (Q1, Q2, Q3).  \\n\\nI would like to have some ideas regarding the model:\\n\\n<ol>\\n<li>Is this the best model to estimate the coefficients accurately?</li>\\n<li>Should I be worried about endogeneity?</li>\\n<li>Is there any way to impose (or test) diminishing returns for the investment in advertisement?</li>\\n</ol>\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['question'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = np.array(df_final['forum'])\n",
    "X = df_final.drop('forum', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have splitted data to train and test let's finally preprocess question column. Remember that you cannot just input words-they must be in numerical form. Keras has a lot of [methods](https://keras.io/preprocessing/text/#tokenizer) to tackle that issue.\n",
    "\n",
    "In this tutorial, we use a tokenizer that splits sentences into words in form of indices in a word dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit tokenizer on training data (build the vocabulary of words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(list(X_train['question'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And look up the word indices in the tokenizer model for our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tokenized = tokenizer.texts_to_sequences(list(X_train['question'].values))\n",
    "X_test_tokenized = tokenizer.texts_to_sequences(list(X_test['question'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we will be training in mini-baches that need to fit into a numpy array, we need our sentences to have the same number of words. We can achieve this by a method called padding. Padding simply fills up our sentences (list of word indices) with zeros until there are at least `maxlen` words in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_padded = sequence.pad_sequences(X_train_tokenized, maxlen=150)\n",
    "X_test_padded = sequence.pad_sequences(X_test_tokenized, maxlen=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect what padding did to our data. We can see that before padding, we had 70 words in sentence 155:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_tokenized[155])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After padding, we have exactly 150:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[155].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the missing words were filled up with zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     9,\n",
       "         239,   430,    41,    23,   323,   334,    77,   174,   112,\n",
       "         140,   698,   235,    13,    17,     1,   179,   342,   356,\n",
       "           4,  1027,  2083,    15,   152,     2,    50,    33,   136,\n",
       "         162,   356,    11,     1,  2097,   334,     6,    41,     3,\n",
       "        1806,     5,  1584,   179,   342,    11,    55,  2097,   169,\n",
       "          30,     6,    41,    64,   204,     9,  2097,    11,  2083,\n",
       "          15,    30,    58,   539,    17,     4,  1027,    71,     1,\n",
       "         212, 11104, 10478,     9,  2097,   221], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_padded[155]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the last step, do not forget to turn the target columns into an one-hot encoded array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "Y_train = np.eye(3)[le.fit_transform(y_train).reshape(-1)]\n",
    "Y_test = np.eye(3)[le.transform(y_test).reshape(-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling our first network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's inspect data that we obtained. Figuring out right shapes is crucial.\n",
    "\n",
    "In this dataset we have..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timesteps = X_train_padded.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the input layer, which just takes in our data. It does not contain any logic other than defining the shape of our input. Since we use the functional API, this also means that all matrix shapes in the following layers will be inferred automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = Input(shape=(timesteps, ), name=\"inputs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To model words we use an `Embedding` layer.\n",
    "\n",
    "The embedding layer turns positive integers (indexes) into dense vectors of fixed size. eg. [[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]. The first parameter defines how many words are in the dictionary, the second parameter defines the size of the vector the input is reduced to.\n",
    "\n",
    "Skip-gram, CBOW, and GloVe (or any other word2vec variant) are pre-trained word embeddings which can be set as the weight of an embedding layer. If the weight of this layer (generally the first layer of the network) is not initialized by these pre-trained vectors, the model/network itself would assign random weights and will learn the embeddings (i.e. weights) on the fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Embedding(len(tokenizer.word_index)+1, 32, mask_zero=True)(input) # +1 for the vocabulary sign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the fun parts starts. We will add an LSTM layer that builds a representation of each posted question based on the words in the sentence.\n",
    "\n",
    "Remember the unfolding in time computation graph for an RNN\n",
    "\n",
    "![image](http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/09/rnn.jpg)\n",
    "\n",
    "where $x_t$ are words in particular question, e.g. $x_1$ is the first word and $x_2$ is the second word. In our case, we are only interested in the last output $o_t$ where $t$ corresponds to the last word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = LSTM(10)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost done! Let's wire up the 10 output neurons of the LSTM to 3 output neurons using a [Dense](https://keras.io/layers/core/#dense) layer (because we have 3 output classes). A Dense layer is just your regular fully connected NN layer. The softmax activation function squeezes these 3 numbers such that they sum up to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output = Dense(3, activation='softmax', name='output')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's wrap up the input and output of our Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input=input, output=output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will compile our model. Here, we specify two parameters:\n",
    "\n",
    "- optimizer: an optimizer does all the work for us. Given the input and the computed errors, it decides which direction to take. There are quite a few [optimizers available in Keras](https://keras.io/optimizers/).\n",
    "- loss: the loss or objective function tells the model how well we are doing on our data. In our case, this is simply categorical crossentropy, but in other cases this may be e.g. mean squared error or binary crossentropy. Note that this function needs to be differentiable because during training we need to be able to compute the weight updates. Hence, we cannot optimize for e.g. ROCAUC directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Nadam(), loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print out a nice plot of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"304pt\" viewBox=\"0.00 0.00 328.00 304.00\" width=\"328pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 300)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-300 324,-300 324,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140239140761424 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140239140761424</title>\n",
       "<polygon fill=\"none\" points=\"32.5,-249.5 32.5,-295.5 287.5,-295.5 287.5,-249.5 32.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"91\" y=\"-268.8\">inputs: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"149.5,-249.5 149.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"177\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"149.5,-272.5 204.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"177\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-249.5 204.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-280.3\">(None, 150)</text>\n",
       "<polyline fill=\"none\" points=\"204.5,-272.5 287.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-257.3\">(None, 150)</text>\n",
       "</g>\n",
       "<!-- 140239156510928 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140239156510928</title>\n",
       "<polygon fill=\"none\" points=\"0,-166.5 0,-212.5 320,-212.5 320,-166.5 0,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-185.8\">embedding_1: Embedding</text>\n",
       "<polyline fill=\"none\" points=\"161,-166.5 161,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"161,-189.5 216,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"216,-166.5 216,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-197.3\">(None, 150)</text>\n",
       "<polyline fill=\"none\" points=\"216,-189.5 320,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"268\" y=\"-174.3\">(None, 150, 32)</text>\n",
       "</g>\n",
       "<!-- 140239140761424&#45;&gt;140239156510928 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140239140761424-&gt;140239156510928</title>\n",
       "<path d=\"M160,-249.366C160,-241.152 160,-231.658 160,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-222.607 160,-212.607 156.5,-222.607 163.5,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140239946082576 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140239946082576</title>\n",
       "<polygon fill=\"none\" points=\"31.5,-83.5 31.5,-129.5 288.5,-129.5 288.5,-83.5 31.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"80.5\" y=\"-102.8\">lstm_1: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"129.5,-83.5 129.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"129.5,-106.5 184.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"157\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"184.5,-83.5 184.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.5\" y=\"-114.3\">(None, 150, 32)</text>\n",
       "<polyline fill=\"none\" points=\"184.5,-106.5 288.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.5\" y=\"-91.3\">(None, 10)</text>\n",
       "</g>\n",
       "<!-- 140239156510928&#45;&gt;140239946082576 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140239156510928-&gt;140239946082576</title>\n",
       "<path d=\"M160,-166.366C160,-158.152 160,-148.658 160,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-139.607 160,-129.607 156.5,-139.607 163.5,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140239153839440 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140239153839440</title>\n",
       "<polygon fill=\"none\" points=\"48.5,-0.5 48.5,-46.5 271.5,-46.5 271.5,-0.5 48.5,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"94.5\" y=\"-19.8\">output: Dense</text>\n",
       "<polyline fill=\"none\" points=\"140.5,-0.5 140.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"140.5,-23.5 195.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"168\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"195.5,-0.5 195.5,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233.5\" y=\"-31.3\">(None, 10)</text>\n",
       "<polyline fill=\"none\" points=\"195.5,-23.5 271.5,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"233.5\" y=\"-8.3\">(None, 3)</text>\n",
       "</g>\n",
       "<!-- 140239946082576&#45;&gt;140239153839440 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140239946082576-&gt;140239153839440</title>\n",
       "<path d=\"M160,-83.3664C160,-75.1516 160,-65.6579 160,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"163.5,-56.6068 160,-46.6068 156.5,-56.6069 163.5,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that *None* simply means that the model does not really care how many instances we input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train using a mini-batch size of 50 instances at a time. This speeds up things, because a mini-batch can be computed in parallel on a GPU. We train for eight epochs, i.e. we go over our training set three times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please leave *verbose* at 2** in the following call, otherwise your notebook may freeze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "inputs (InputLayer)              (None, 150)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 150, 32)       1716704     inputs[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 10)            1720        embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "output (Dense)                   (None, 3)             33          lstm_1[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 1718457\n",
      "____________________________________________________________________________________________________\n",
      "Train on 9707 samples, validate on 2427 samples\n",
      "Epoch 1/4\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "model.fit(X_train_padded, Y_train, verbose=2, nb_epoch=4, batch_size=bs, validation_data=(X_test_padded, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Increase the number of neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe the model is simply to small to accomodate patterns in our data? Let's try to increase our neurons!\n",
    "\n",
    "**Your task** is to:\n",
    "\n",
    "- Mark this chunk and select *Cell* and then *Run All Above*\n",
    "- Increase the number of neurons to 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(timesteps,), name=\"inputs\")\n",
    "x = input\n",
    "\n",
    "### Your code here\n",
    "x = Embedding(len(tokenizer.word_index)+1, 32, mask_zero=True)(x)\n",
    "x = LSTM(20)(x)\n",
    "###\n",
    "\n",
    "output = Dense(3, activation='softmax', name='output')(x)\n",
    "model1 = Model(input=input, output=output)\n",
    "model.summary()\n",
    "model1.compile(optimizer=Nadam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1.fit(X_train_padded, Y_train, verbose=2, nb_epoch=4, batch_size=bs, validation_data=(X_test_padded, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Use Bidirectional layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make our model deeper! This is deep learning after all. Note that our network is already deep in time, i.e. we take into consideration 150 time steps. But we can also make it deeper vertically.\n",
    "\n",
    "Your task is to\n",
    "\n",
    "- instead of LSTM use Bidirectional LSTM layer with 20 neurons\n",
    "\n",
    "- Next, add another bidirectional LSTM layer.\n",
    "At each time step, the first LSTM will feed into the second LSTM. This is called stacking.\n",
    "\n",
    "Note that for this, you have to set *return_sequences=True* in the first LSTM. Do you understand why this is required?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(timesteps,), name=\"inputs\")\n",
    "x = input\n",
    "\n",
    "### Your code goes here:\n",
    "x = Embedding(len(tokenizer.word_index)+1, 32, mask_zero=True)(x)\n",
    "x = Bidirectional(LSTM(20, return_sequences=True))(x)\n",
    "x = Bidirectional(LSTM(20))(x)\n",
    "##\n",
    "\n",
    "output = Dense(3, activation='softmax', name='output')(x)\n",
    "model2 = Model(input=input, output=output)\n",
    "model2.compile(optimizer=Nadam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model2, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X_train_padded, Y_train, verbose=2, nb_epoch=4, batch_size=bs, validation_data=(X_test_padded, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Add regularization\n",
    "\n",
    "There are two major ways by which you can regularize model and descrease overfitting.\n",
    "\n",
    "1. Dropout-it randomly sets a fraction *rate* of input units to 0 at each update during training time\n",
    "2. L2 regularizer\n",
    "\n",
    "\n",
    "Your task is to add dropout to the Model. Dropout is just another layer you can add to your model definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(timesteps,), name=\"inputs\")\n",
    "x = input\n",
    "\n",
    "### Your code goes here:\n",
    "x = Embedding(len(tokenizer.word_index)+1, 32, mask_zero=True)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Bidirectional(LSTM(20, return_sequences=True))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Bidirectional(LSTM(20))(x)\n",
    "x = Dropout(0.5)(x)\n",
    "##\n",
    "\n",
    "output = Dense(3, activation='softmax', name='output')(x)\n",
    "model3 = Model(input=input, output=output)\n",
    "model3.compile(optimizer=Nadam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.fit(X_train_padded, Y_train, verbose=2, nb_epoch=4, batch_size=bs, validation_data=(X_test_padded, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Feature Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task will be a bit more challenging. We are going to use an additional attribute: tags on forum. However, because this attribute is constant we will not add it to LSTM that summarizes the time series.\n",
    "\n",
    "Instead, we will *merge* the $n$-dimensional vector output of the LSTM with a $m$-dimensional vector, where merging means concatenating the two vectors into a vector of dimensionality $n+m$.\n",
    "\n",
    "Conveniently, we have already encoded tags as a one-hot vector, i.e. the columns in the following matrix correspond to unique tags. Note that matrix is very sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags_train = np.array(X_train.drop('question', axis=1))\n",
    "tags_test = np.array(X_test.drop('question', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, you have to do the following:\n",
    "\n",
    "- Use the solution from the previous task.\n",
    "- Create a second Input with shape `(number_of_tags, )`.\n",
    "- Introduce a [Merge](https://keras.io/getting-started/sequential-model-guide/#the-merge-layer) layer that merges `[x, your_new_input]`. This can be done using the `merge` **function** (not the `Merge` class).\n",
    "- Modify the `Model` instantiation to take two inputs simultaneously, similar to what you have done in the previous step.\n",
    "\n",
    "Note that you have to implement all of the above tasks before your model actually works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(timesteps,), name=\"inputs\")\n",
    "\n",
    "### Your code here\n",
    "number_of_tags = tags_train.shape[1]\n",
    "input2 = Input(shape=(number_of_tags,), name='inputs2')\n",
    "\n",
    "x = Embedding(len(tokenizer.word_index)+1, 32)(input)\n",
    "x = LSTM(20)(x)\n",
    "x = Merge([x, input2], mode=\"concat\")\n",
    "\n",
    "###\n",
    "\n",
    "output = Dense(3, activation='softmax', name='output')(x)\n",
    "model4 = Model(input=[input, input2], output=output)\n",
    "model4.compile(optimizer=Nadam(), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVG(model_to_dot(model3, show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model4.fit([X_train_padded, tags_train], Y_train, verbose=2, nb_epoch=4, batch_size=bs, validation_split=([X_test_padded, tags_test], Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's still getting better! This concludes the second deep learning tutorial.\n",
    "\n",
    "If you still have some free time, you are welcome to experiment further with our architecture. Things you may want to try:\n",
    "\n",
    "- Use GRU instead of LSTM units\n",
    "- Change the number of neurons in the LSTM"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
